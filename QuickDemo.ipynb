{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Libraries/')\n",
    "import pclpy\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pdal\n",
    "import segTree\n",
    "import Visualization\n",
    "import Utils\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Utils\n",
    "def tic():\n",
    "    global timestart\n",
    "    timestart = time.perf_counter()\n",
    "    \n",
    "def toc():\n",
    "    global timestart\n",
    "    return time.perf_counter()-timestart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PointCloud = pclpy.pcl.PointCloud.PointXYZ()\n",
    "pclpy.pcl.io.loadPCDFile('D:/Documentos/ParaAutonomia/Python/Proyecto/Data/NistClouds/downsampledlesscloudEURO1.pcd',PointCloud)\n",
    "Visualization.PCL3dpaint(PointCloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Cloud and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PDAL to apply a Morphological Filter to seperate ground and non ground points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllGround = []\n",
    "AllNonGround = []  \n",
    "Nogroundpoints,ground = segTree.FloorRemove(PointCloud)\n",
    "\n",
    "NongroundCloud = pclpy.pcl.PointCloud.PointXYZ(Nogroundpoints)\n",
    "GroundCloud = pclpy.pcl.PointCloud.PointXYZ(ground)\n",
    "\n",
    "Visualization.PCL3dpaint([NongroundCloud,GroundCloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Algorithm Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verticalityThresh = 0.06\n",
    "NonNANcurvatureThresh = 0.1\n",
    "\n",
    "lowstems_Height = 5\n",
    "cutstems_Height = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omara\\anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:59: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "#Get point normals for filtering\n",
    "\n",
    "Ksearch = 0.08\n",
    "normals = segTree.ExtractNormals(NongroundCloud.xyz, Ksearch)\n",
    "Visualization.PCL3dpaint([NongroundCloud.xyz,NongroundCloud.xyz+normals.normals*0.1,NongroundCloud.xyz+normals.normals*0.2])\n",
    "\n",
    "nanmask = np.bitwise_not(np.isnan(normals.normals[:,0]))\n",
    "NonNANpoints = NongroundCloud.xyz[nanmask]\n",
    "NonNANnormals = normals.normals[nanmask]\n",
    "NonNANcurvature = normals.curvature[nanmask]\n",
    "verticality = np.dot(NonNANnormals,[[0],[0],[1]])\n",
    "mask = (verticality < verticalityThresh) & (-verticalityThresh < verticality)  #0.1\n",
    "maskC = (NonNANcurvature < NonNANcurvatureThresh)## 0.12\n",
    "Fmask = mask.ravel() & maskC.ravel()\n",
    "\n",
    "onlyhorizontalpoints = NonNANpoints[Fmask]\n",
    "onlyhorizontalnormals = NonNANnormals[Fmask]\n",
    "\n",
    "Visualization.PCL3dpaint([onlyhorizontalpoints,onlyhorizontalpoints+onlyhorizontalnormals*0.05,onlyhorizontalpoints+onlyhorizontalnormals*0.1])\n",
    "\n",
    "cluster_list = segTree.EucladeanClusterExtract(onlyhorizontalpoints, tol=0.1, minc=40, maxc=6000000)\n",
    "Visualization.PCL3dpaint(cluster_list)\n",
    "\n",
    "#Group stem segments\n",
    "GroupStems = []\n",
    "\n",
    "bufferStems = cluster_list.copy()\n",
    "for n,p in enumerate(cluster_list):\n",
    "    Centroid = np.mean(p, axis = 0)\n",
    "    _, S,vT = np.linalg.svd(p-Centroid)\n",
    "    strieghtness = S[0]/(S[0]+S[1]+S[2])\n",
    "    \n",
    "    clustersDICT = {}\n",
    "    clustersDICT['cloud'] = p\n",
    "    clustersDICT['strieghtness'] = strieghtness\n",
    "    clustersDICT['center'] = Centroid\n",
    "    clustersDICT['direction'] = vT\n",
    "    GroupStems.append(clustersDICT)\n",
    "\n",
    "bufferStems = [i['cloud'] for i in GroupStems]\n",
    "for treenumber1 in reversed(range(0,len(bufferStems))):\n",
    "    for treenumber2 in reversed(range(0,treenumber1-1)):\n",
    "        center1 = GroupStems[treenumber1]['center']\n",
    "        center2 = GroupStems[treenumber2]['center']\n",
    "        angle1 = GroupStems[treenumber1]['direction'][0]\n",
    "        angle2 = GroupStems[treenumber2]['direction'][0]\n",
    "        dist1 = Utils.DistPoint2Line(center2,angle1+center1,center1)\n",
    "        dist2 = Utils.DistPoint2Line(center1,angle2+center2,center2)\n",
    "        if (dist1<0.4) | (dist2<0.4):\n",
    "            bufferStems[treenumber2] = np.vstack([bufferStems[treenumber2],bufferStems.pop(treenumber1)])\n",
    "            break\n",
    "\n",
    "            \n",
    "Visualization.PCL3dpaint(bufferStems)\n",
    "\n",
    "pointpart = GroundCloud.xyz\n",
    "#groundseg = groundCloud.xyz[center]\n",
    "A = np.c_[np.ones(pointpart.shape[0]), pointpart[:,:2], np.prod(pointpart[:,:2], axis=1), pointpart[:,:2]**2]\n",
    "C,_,_,_ = np.linalg.lstsq(A, pointpart[:,2])\n",
    "#Corners.PCL3dpaint(cluster_list)\n",
    "\n",
    "StemsWithGround = []\n",
    "for i in bufferStems:\n",
    "    center = np.mean(i,0)\n",
    "    X,Y = center[:2]\n",
    "    Z = np.dot(np.c_[np.ones(X.shape), X, Y, X*Y, X**2, Y**2], C)\n",
    "    StemsWithGround.append([i,[X,Y,Z[0]]])\n",
    "\n",
    "#lowStems = [i for i in StemsWithGround if np.min(i[0],axis=0)[2] < (3 + i[1][2])]\n",
    "#cutstems = [i[i[:,2]<(3+np.min(i[:,2]))] for i in lowStems]\n",
    "\n",
    "lowStems = [i for i in StemsWithGround if np.min(i[0],axis=0)[2] < (lowstems_Height + i[1][2])]\n",
    "cutstems = [[i[0][i[0][:,2]<(cutstems_Height + i[1][2])],i[1]] for i in lowStems]\n",
    "\n",
    "Visualization.PCL3dpaint([i[0] for i in cutstems])\n",
    "\n",
    "finalstems = []\n",
    "stemcyls = []\n",
    "rech = []\n",
    "for p in cutstems:\n",
    "    segpoints = p[0]\n",
    "    indices, model = segTree.segment_normals(segpoints, searchRadius=0.1, model=pclpy.pcl.sample_consensus.SACMODEL_CYLINDER, method=pclpy.pcl.sample_consensus.SAC_RANSAC, normalweight=0.01, miter=10000, distance=0.08, rlim=[0,0.4])\n",
    "    if len(indices)>0:\n",
    "        if abs(np.dot(model[3:6],[0,0,1])/np.linalg.norm(model[3:6])) > 0.5:\n",
    "            newmodel = np.array(model)\n",
    "            Z = 1.3 + p[1][2]\n",
    "            Y = model[1] + model[4] * (Z - model[2]) / model[5]\n",
    "            X = model[0] + model[3] * (Z - model[2]) / model[5]\n",
    "            newmodel[0:3] = np.array([X,Y,Z])\n",
    "            newmodel[3:6] = Utils.similarize(newmodel[3:6],[0,0,1])\n",
    "            finalstems.append({'tree':segpoints[indices],'model':newmodel})\n",
    "            stemcyls.append(Utils.makecylinder(model=newmodel,length=7,dense=60))\n",
    "        else:\n",
    "            rech.append(segpoints)\n",
    "    else:\n",
    "        rech.append(segpoints)\n",
    "\n",
    "Visualization.PCL3dpaint([i['tree'] for i in finalstems] + stemcyls)\n",
    "        \n",
    "\n",
    "#####################################################\n",
    "#Get ground truth\n",
    "treedata = pd.read_csv('D:/Documentos/ParaAutonomia/Python/Proyecto/Data/EuroSDR_DataRelease/EuroSDR_DataRelease/TLS_Benchmarking_Plot_1_LHD.txt',sep = '\\t',names = ['x','y','height','DBH'])\n",
    "Xcor,Ycor,diam = treedata.iloc[0,[0,1,3]]\n",
    "surtreesL1 = [Utils.makecylinder(model=[Xcor, Ycor, 0,0,0,1,diam/2],length=10,dense=20)]\n",
    "Zcor = 0\n",
    "TreeDict = [np.array([Xcor,Ycor,diam])]\n",
    "for i,rows in treedata.iloc[1:].iterrows():\n",
    "    Xcor,Ycor,diam = rows.iloc[[0,1,3]]\n",
    "    if not np.any(np.isnan([Xcor,Ycor,diam])):\n",
    "        surtreesL1.append(Utils.makecylinder(model=[Xcor, Ycor, 0,0,0,1,diam/2],length=10,dense=10))\n",
    "        TreeDict.append(np.array([Xcor,Ycor,diam]))\n",
    "surtrees1 = [p for i in surtreesL1 for p in i]\n",
    "surtreesCloud1 = pclpy.pcl.PointCloud.PointXYZ(surtrees1)\n",
    "\n",
    "            #DataBase\n",
    "#Found trees\n",
    "#Hungarian Algorithm assignment\n",
    "CostMat = np.ones([len(TreeDict),len(stemcyls)])\n",
    "for X,datatree in enumerate(TreeDict):\n",
    "    for Y,foundtree in enumerate(finalstems):\n",
    "        CostMat[X,Y] = np.linalg.norm([datatree[0:2]-foundtree['model'][0:2]])\n",
    "\n",
    "dataindex, foundindex = linear_sum_assignment(CostMat,maximize=False)\n",
    "\n",
    "#Get metrics\n",
    "locationerror = []\n",
    "correctlocationerror = []\n",
    "diametererror = []\n",
    "cloudmatch = []\n",
    "for i,j in zip(dataindex, foundindex):\n",
    "    locationerror.append(np.linalg.norm((finalstems[j]['model'][0:2]-TreeDict[i][0:2])))\n",
    "    if locationerror[-1]<0.4:\n",
    "        diametererror.append(abs(finalstems[j]['model'][6]*2-TreeDict[i][2]))        \n",
    "        correctlocationerror.append(np.linalg.norm((finalstems[j]['model'][0:2]-TreeDict[i][0:2])))\n",
    "    cloudmatch.append(np.vstack([surtreesL1[i],finalstems[j]['tree'],stemcyls[j]]))\n",
    "\n",
    "#PCA filtering and Eucladian Clustering\n",
    "Visualization.PCL3dpaint(cloudmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Methods = ['CAF','TUDelft','FGI','IntraIGN','RADI','NJU','Shinshu','SLU','TUZVO','TUWien','RILOG','TreeMetrics','UofL','WHU']\n",
    "CompletenessEasy = [88, 66, 94, 84, 74, 88, 89, 94, 87, 82, 96, 36, 69, 89]\n",
    "CompletenessMedium = [75, 49, 88, 65, 59, 81, 78, 88, 74, 68, 87, 27, 58, 80]\n",
    "CompletenessHard = [44, 16, 66, 27, 25, 45, 46, 64, 39, 39, 63, 18, 37, 52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "StemRMSEEasy = [22, 154, 28, 12, 32, 132, 52, 20, 20, 16, 32, 30, 88, 58]\n",
    "StemRMSEMedium = [32, 182, 30, 40, 48, 200, 80, 42, 36, 26, 64, 26, 116, 82]\n",
    "StemRMSEHard = [40, 273, 64, 70, 80, 200, 120, 66, 82, 48, 112, 24, 144, 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBHRMSEEasy = [20, 128, 14, 16, 20, 210, 48, 18, 22, 14, 86, 12, 62, 72]\n",
    "DBHRMSEMedium = [22, 122, 18, 34, 40, 240, 80, 32, 34, 16, 110, 20, 84, 96]\n",
    "DBHRMSEHard = [18, 174, 20, 300, 74, 250, 94, 30, 36, 12, 174, 24, 94, 124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
